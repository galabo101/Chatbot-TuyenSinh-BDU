"""
Cross-Encoder Reranker - Thay tháº¿ RelevanceEvaluator (LLM-based)
Sá»­ dá»¥ng model local Ä‘á»ƒ rerank documents, giáº£m latency tá»« ~1-2s xuá»‘ng ~0.1-0.3s
"""

from typing import List, Dict, Tuple
from sentence_transformers import CrossEncoder
import numpy as np


class CrossEncoderReranker:
    """
    Reranker sá»­ dá»¥ng Cross-Encoder Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ Ä‘á»™ liÃªn quan
    Thay tháº¿ cho RelevanceEvaluator (LLM-based) trong CRAG
    """
    
    def __init__(
        self,
        model_name: str = "cross-encoder/ms-marco-MiniLM-L-6-v2",
        preloaded_model: CrossEncoder = None
    ):
        """
        Args:
            model_name: TÃªn model Cross-Encoder
                - "cross-encoder/ms-marco-MiniLM-L-6-v2" (nhá», nhanh, ~80MB)
                - "BAAI/bge-reranker-base" (lá»›n hÆ¡n, chÃ­nh xÃ¡c hÆ¡n, ~400MB)
            preloaded_model: Model Ä‘Ã£ load sáºµn (Ä‘á»ƒ trÃ¡nh load láº¡i)
        """
        if preloaded_model:
            print("âœ… Using preloaded Cross-Encoder model")
            self.model = preloaded_model
        else:
            print(f"ğŸ”§ Loading Cross-Encoder: {model_name}")
            self.model = CrossEncoder(model_name)
            print("âœ… Cross-Encoder ready")
        
        # Thresholds cho viá»‡c phÃ¢n loáº¡i (tÆ°Æ¡ng Ä‘Æ°Æ¡ng CORRECT/AMBIGUOUS/INCORRECT)
        # âœ… Giáº£m threshold Ä‘á»ƒ giá»¯ láº¡i nhiá»u chunks chi tiáº¿t hÆ¡n
        self.high_threshold = 0.5   # >= 0.5: CORRECT (giáº£m tá»« 0.7)
        self.low_threshold = 0.2    # < 0.2: INCORRECT (giáº£m tá»« 0.3)
    
    def get_scores(self, query: str, documents: List[Dict]) -> List[float]:
        """
        TÃ­nh Ä‘iá»ƒm relevance cho má»—i document
        
        Args:
            query: CÃ¢u há»i cá»§a user
            documents: List[Dict] vá»›i key 'content' hoáº·c 'full_content'
            
        Returns:
            List[float]: Äiá»ƒm relevance (0-1) cho má»—i document
        """
        if not documents:
            return []
        
        # Chuáº©n bá»‹ pairs (query, document_content)
        pairs = []
        for doc in documents:
            content = doc.get("full_content") or doc.get("content", "")
            # Giá»›i háº¡n Ä‘á»™ dÃ i Ä‘á»ƒ tÄƒng tá»‘c
            content = content[:1000] if len(content) > 1000 else content
            pairs.append([query, content])
        
        # TÃ­nh Ä‘iá»ƒm
        scores = self.model.predict(pairs)
        
        # Normalize vá» 0-1 (ms-marco model tráº£ vá» logits, cáº§n sigmoid)
        normalized_scores = 1 / (1 + np.exp(-np.array(scores)))
        
        return normalized_scores.tolist()
    
    def rerank(
        self, 
        query: str, 
        documents: List[Dict], 
        top_k: int = None
    ) -> List[Dict]:
        """
        Rerank documents theo Ä‘á»™ liÃªn quan
        
        Args:
            query: CÃ¢u há»i cá»§a user
            documents: List documents cáº§n rerank
            top_k: Sá»‘ lÆ°á»£ng documents tráº£ vá» (None = táº¥t cáº£)
            
        Returns:
            List[Dict]: Documents Ä‘Ã£ Ä‘Æ°á»£c sáº¯p xáº¿p theo Ä‘iá»ƒm giáº£m dáº§n
        """
        if not documents:
            return []
        
        scores = self.get_scores(query, documents)
        
        # Gáº¯n score vÃ o documents
        for doc, score in zip(documents, scores):
            doc["rerank_score"] = score
        
        # Sáº¯p xáº¿p theo Ä‘iá»ƒm giáº£m dáº§n
        sorted_docs = sorted(documents, key=lambda x: x["rerank_score"], reverse=True)
        
        if top_k:
            sorted_docs = sorted_docs[:top_k]
        
        return sorted_docs
    
    def grade_documents(
        self, 
        query: str, 
        documents: List[Dict]
    ) -> Dict[str, List[Dict]]:
        """
        PhÃ¢n loáº¡i documents thÃ nh CORRECT/AMBIGUOUS/INCORRECT
        (TÆ°Æ¡ng thÃ­ch vá»›i interface cÅ© cá»§a RelevanceEvaluator)
        
        Args:
            query: CÃ¢u há»i cá»§a user
            documents: List documents cáº§n Ä‘Ã¡nh giÃ¡
            
        Returns:
            Dict vá»›i keys: 'correct', 'ambiguous', 'incorrect'
        """
        if not documents:
            return {"correct": [], "ambiguous": [], "incorrect": []}
        
        scores = self.get_scores(query, documents)
        
        graded = {
            "correct": [],
            "ambiguous": [],
            "incorrect": []
        }
        
        for doc, score in zip(documents, scores):
            doc["rerank_score"] = score
            
            if score >= self.high_threshold:
                graded["correct"].append(doc)
            elif score >= self.low_threshold:
                graded["ambiguous"].append(doc)
            else:
                graded["incorrect"].append(doc)
        
        # Log káº¿t quáº£
        print(f"[CrossEncoder] Grading results:")
        print(f"   âœ… CORRECT: {len(graded['correct'])}")
        print(f"   âš ï¸  AMBIGUOUS: {len(graded['ambiguous'])}")
        print(f"   âŒ INCORRECT: {len(graded['incorrect'])}")
        
        return graded


# Singleton Ä‘á»ƒ preload model
_reranker_instance = None

def get_reranker(model_name: str = "cross-encoder/ms-marco-MiniLM-L-6-v2") -> CrossEncoderReranker:
    """
    Factory function Ä‘á»ƒ láº¥y singleton instance
    TrÃ¡nh load model nhiá»u láº§n
    """
    global _reranker_instance
    if _reranker_instance is None:
        _reranker_instance = CrossEncoderReranker(model_name=model_name)
    return _reranker_instance
