import time
import os
import numpy as np
from dotenv import load_dotenv
from groq import Groq

load_dotenv()

# Test prompt
TEST_PROMPT = """B·∫°n l√† tr·ª£ l√Ω tuy·ªÉn sinh. D·ª±a tr√™n th√¥ng tin sau, h√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn:

TH√îNG TIN:
- Ng√†nh CNTT: H·ªçc ph√≠ 8tr/k·ª≥, ƒêi·ªÉm chu·∫©n 16.
- Ng√†nh D∆∞·ª£c: H·ªçc ph√≠ 15tr/k·ª≥, ƒêi·ªÉm chu·∫©n 21.

C√ÇU H·ªéI: So s√°nh h·ªçc ph√≠ ng√†nh D∆∞·ª£c v√† CNTT?

TR·∫¢ L·ªúI:"""

def benchmark_groq_model(model_name: str, num_runs: int = 10):
    """H√†m chung ƒë·ªÉ benchmark c√°c model tr√™n Groq"""
    print(f"\n{'='*60}")
    print(f"üöÄ Benchmarking: {model_name}")
    print(f"{'='*60}")
    
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        print("‚ùå GROQ_API_KEY missing")
        return None
    
    client = Groq(api_key=api_key)
    
    # 1. Warm-up (Ki·ªÉm tra xem model c√≥ t·ªìn t·∫°i kh√¥ng)
    print("Warming up...", end=" ")
    try:
        client.chat.completions.create(
            messages=[{"role": "user", "content": "hi"}],
            model=model_name,
            max_tokens=10
        )
        print("‚úÖ Ready!")
    except Exception as e:
        print(f"\n‚ùå Model Error: {e}")
        print("üëâ G·ª£i √Ω: Ki·ªÉm tra l·∫°i t√™n model trong config.py. Groq th∆∞·ªùng h·ªó tr·ª£: llama-3.3-70b, mixtral-8x7b...")
        return None

    times = []
    tokens_per_sec = []
    
    print(f"Running {num_runs} iterations...")
    for i in range(num_runs):
        start = time.time()
        try:
            resp = client.chat.completions.create(
                messages=[{"role": "user", "content": TEST_PROMPT}],
                model=model_name,
                max_tokens=200,
                temperature=0.1
            )
            elapsed = (time.time() - start) * 1000 # ms
            
            # T√≠nh t·ªëc ƒë·ªô
            n_tokens = resp.usage.completion_tokens
            tps = n_tokens / (elapsed / 1000)
            
            times.append(elapsed)
            tokens_per_sec.append(tps)
            
            # In ti·∫øn ƒë·ªô g·ªçn
            print(f"  [{i+1}/{num_runs}] Time: {elapsed:.0f}ms | Speed: {tps:.0f} t/s")
            
            # Ng·ªß nh·∫π ƒë·ªÉ tr√°nh rate limit c·ªßa Groq
            time.sleep(0.5)
                
        except Exception as e:
            print(f"  ‚ùå Request failed: {e}")
            time.sleep(1)
            
    return {
        "name": model_name,
        "time": np.array(times),
        "speed": np.array(tokens_per_sec)
    }

if __name__ == "__main__":
    results = []
    
    # 1. Benchmark Model Ch√≠nh
    r1 = benchmark_groq_model("llama-3.3-70b-versatile", num_runs=10)
    if r1: results.append(r1)
    
    # 2. Benchmark Model D·ª± ph√≤ng (Theo config c·ªßa b·∫°n)
    # L∆∞u √Ω: N·∫øu t√™n model sai, n√≥ s·∫Ω b√°o l·ªói ·ªü b∆∞·ªõc Warm-up
    r2 = benchmark_groq_model("openai/gpt-oss-120b", num_runs=10)
    if r2: results.append(r2)
    
    # Summary Table
    if results:
        print(f"\n\n{'='*85}")
        print(f"{'MODEL':<30} | {'AVG TIME (ms)':<15} | {'SPEED (tok/s)':<15} | {'SCORE'}")
        print(f"{'-'*85}")
        
        # L·∫•y t·ªëc ƒë·ªô cao nh·∫•t l√†m chu·∫©n
        max_speed = max(r['speed'].mean() for r in results)
        
        for r in results:
            avg_time = r['time'].mean()
            avg_speed = r['speed'].mean()
            score = avg_speed / max_speed * 100 # % so v·ªõi model nhanh nh·∫•t
            
            print(f"{r['name']:<30} | {avg_time:>13.0f} | {avg_speed:>13.0f} | {score:>4.0f}%")
        print(f"{'='*85}\n")
    else:
        print("\n‚ö†Ô∏è Kh√¥ng c√≥ k·∫øt qu·∫£ n√†o th√†nh c√¥ng.")